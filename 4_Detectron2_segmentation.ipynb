{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAzUj4z57plR"
      },
      "source": [
        "# An introduction to Detectron2 <p>\n",
        "Using pre-trained models for instance and panoptic segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEzT6ktj71cQ"
      },
      "source": [
        "Install the Detectron2 library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_lPuyTT7H6v"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reihZiCA7d29"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hagrMdJ7j_b"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "#from detectron2.utils.logger import setup_logger\n",
        "#setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uytaQ0yw_Yps"
      },
      "source": [
        "Read an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQlI33v_7P0O"
      },
      "outputs": [],
      "source": [
        "my_new_image = cv2.imread(\"/content/images1.jpg\")\n",
        "cv2_imshow(my_new_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjryKakG9zDf"
      },
      "source": [
        "**Keypoint detection model** <p>\n",
        "Keypoints are specific locations or landmarks in an image that are distinctive and informative. These keypoints are selected because they represent significant variations in the local image region and can be reliably detected and matched across different images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRq0olFc9e3Q"
      },
      "outputs": [],
      "source": [
        "# Inference with a keypoint detection model\n",
        "cfg_keypoint = get_cfg()   # get a fresh new config\n",
        "cfg_keypoint.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg_keypoint.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n",
        "cfg_keypoint.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg_keypoint)\n",
        "outputs = predictor(my_new_image)\n",
        "v = Visualizer(my_new_image[:,:,::-1], MetadataCatalog.get(cfg_keypoint.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh1hn_n88L2z"
      },
      "source": [
        "**Instance Segmentation** <p>\n",
        "Instance segmentation is a computer vision task that involves identifying and delineating individual objects within an image by assigning a unique mask to each object instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-qnGOQ97QRY"
      },
      "outputs": [],
      "source": [
        "# Inference with instance segmentation\n",
        "cfg_inst = get_cfg()\n",
        "cfg_inst.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg_inst.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo.  https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md\n",
        "cfg_inst.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg_inst)\n",
        "outputs = predictor(my_new_image)\n",
        "\n",
        "v = Visualizer(my_new_image[:, :, ::-1], MetadataCatalog.get(cfg_inst.DATASETS.TRAIN[0]), scale=1.0)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moCitYFd7Yu8"
      },
      "source": [
        "**Panoptic segmentation = Instance segmentation + Semantic Segmentation**\n",
        "<p>\n",
        "Panoptic segmentation is a computer vision task that combines instance segmentation and semantic segmentation to label every pixel in an image with both a class category and a unique instance ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb7ApzKj7TbM"
      },
      "outputs": [],
      "source": [
        "# Inference with a panoptic segmentation model\n",
        "cfg_pan = get_cfg()\n",
        "cfg_pan.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
        "cfg_pan.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg_pan)\n",
        "panoptic_seg, segments_info = predictor(my_new_image)[\"panoptic_seg\"]\n",
        "v = Visualizer(my_new_image[:, :, ::-1], MetadataCatalog.get(cfg_pan.DATASETS.TRAIN[0]), scale=1.0)\n",
        "out = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Existing imports and setup (as in your code)\n",
        "import torch, detectron2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load your image (Make sure the image path is correct)\n",
        "my_new_image = cv2.imread(\"/content/images1.jpg\")\n",
        "cv2_imshow(my_new_image)\n",
        "\n",
        "# Semantic Segmentation\n",
        "cfg_sem = get_cfg()\n",
        "cfg_sem.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))  # Panoptic FPN config\n",
        "cfg_sem.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")  # Pre-trained weights\n",
        "cfg_sem.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set a threshold\n",
        "cfg_sem.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
        "\n",
        "# Create predictor for semantic segmentation\n",
        "predictor_sem = DefaultPredictor(cfg_sem)\n",
        "\n",
        "# Perform prediction on the image\n",
        "outputs_sem = predictor_sem(my_new_image)\n",
        "\n",
        "# Extract the semantic segmentation prediction (the mask)\n",
        "panoptic_seg, segments_info = outputs_sem[\"panoptic_seg\"]\n",
        "\n",
        "# Visualize the results\n",
        "v_sem = Visualizer(my_new_image[:, :, ::-1], MetadataCatalog.get(cfg_sem.DATASETS.TRAIN[0]), scale=1.0)\n",
        "out_sem = v_sem.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
        "\n",
        "# Show the semantic segmentation output\n",
        "cv2_imshow(out_sem.get_image()[:, :, ::-1])\n"
      ],
      "metadata": {
        "id": "FZ2Y03hCoGJR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}